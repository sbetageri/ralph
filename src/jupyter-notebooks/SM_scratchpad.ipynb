{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc, delta, logfbank\n",
    "import librosa\n",
    "import torch\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2mp3 = '../data/dev/1KFUSfbcwfw50002.mp3'\n",
    "path2txt = '../data/dev/1KFUSfbcwfw50002.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMP3(f, normalized=False):\n",
    "    \"\"\"MP3 to numpy array\"\"\"\n",
    "    a = pydub.AudioSegment.from_mp3(f)\n",
    "    y = np.array(a.get_array_of_samples())\n",
    "    if a.channels == 2:\n",
    "        y = y.reshape((-1, 2))\n",
    "    if normalized:\n",
    "        return a.frame_rate, np.float32(y) / 2**15\n",
    "    else:\n",
    "        return a.frame_rate, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, sig = readMP3(path2mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90112,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_feat = mfcc(sig,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mfcc_feat = delta(mfcc_feat, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mfcc_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbank_feat = logfbank(sig,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 26)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbank_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc2 = zip(*mfcc(sig,rate)) #mfcc(sig,rate) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc2 = np.stack([np.array(i) for i in mfcc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 562)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.expand_dims(np.expand_dims(mfcc2,axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 13, 562)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cct = torch.autograd.Variable(torch.from_numpy(cc.astype(float)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 13, 562])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_feat_librosa(input_file, dim=13, window_size=25, stride=10, \n",
    "                      feature='mfcc', cmvn=False, delta=False, delta_delta=False, save_feature=None):\n",
    "    y, sr = librosa.load(input_file,sr=None)\n",
    "    ws = int(sr*0.001*window_size)\n",
    "    st = int(sr*0.001*stride)\n",
    "    if feature == 'fbank': # log-scaled\n",
    "        feat = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=dim,\n",
    "                                    n_fft=ws, hop_length=st)\n",
    "        feat = np.log(feat+1e-6)\n",
    "    elif feature == 'mfcc':\n",
    "        feat = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=dim, n_mels=26,\n",
    "                                    n_fft=ws, hop_length=st)\n",
    "        feat[0] = librosa.feature.rmse(y, hop_length=st, frame_length=ws) \n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Unsupported Acoustic Feature: '+feature)\n",
    "\n",
    "    feat = [feat]\n",
    "    if delta:\n",
    "        feat.append(librosa.feature.delta(feat[0]))\n",
    "\n",
    "    if delta_delta:\n",
    "        feat.append(librosa.feature.delta(feat[0],order=2))\n",
    "    feat = np.concatenate(feat,axis=0)\n",
    "    if cmvn:\n",
    "        feat = (feat - feat.mean(axis=1)[:,np.newaxis]) / (feat.std(axis=1)+1e-16)[:,np.newaxis]\n",
    "    if save_feature is not None:\n",
    "        tmp = np.swapaxes(feat,0,1).astype('float32')\n",
    "        np.save(save_feature,tmp)\n",
    "        return len(tmp)\n",
    "    else:\n",
    "        return np.swapaxes(feat,0,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.3055843e-05,  1.3473907e+01, -1.5743690e+00, ...,\n",
       "        -4.4256482e+00,  2.1285338e+00,  5.8058966e-02],\n",
       "       [ 5.2968004e-05,  1.0580042e+01, -3.9050567e+00, ...,\n",
       "         2.5809073e-01,  2.3016870e+00, -5.0932455e+00],\n",
       "       [ 6.6001980e-05,  6.7694855e+00, -1.1243533e+01, ...,\n",
       "         1.2006351e+00,  8.2259731e+00, -9.6584007e-02],\n",
       "       ...,\n",
       "       [ 3.1970714e-05,  0.0000000e+00, -6.2602315e-14, ...,\n",
       "        -7.4604954e-14,  0.0000000e+00,  6.7853838e-14],\n",
       "       [ 0.0000000e+00,  0.0000000e+00, -6.2602315e-14, ...,\n",
       "        -7.4604954e-14,  0.0000000e+00,  6.7853838e-14],\n",
       "       [ 0.0000000e+00,  0.0000000e+00, -6.2602315e-14, ...,\n",
       "        -7.4604954e-14,  0.0000000e+00,  6.7853838e-14]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = get_audio_feat_librosa(path2mp3)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(573, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_feat_psf(input_file, dim=13, window_size=25, stride=10):\n",
    "    sig, rate = librosa.load(input_file, sr=None)\n",
    "    feat = mfcc(sig, samplerate=rate, numcep=dim, winlen=window_size/1000, winstep=stride/1000)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_feat(input_file, dim=13, window_size=25, stride=10, method='psf'):\n",
    "    if method == 'psf':\n",
    "        feat = get_audio_feat_psf(input_file, dim, window_size, stride)\n",
    "    else:\n",
    "        feat = get_audio_feat_librosa(input_file, dim, window_size, stride, cmvn=True)\n",
    "    mfcc = zip(*feat)\n",
    "    mfcc = np.stack([np.array(i) for i in mfcc])\n",
    "    cc = np.expand_dims(mfcc,axis=0)\n",
    "    #cc = np.expand_dims(np.expand_dims(mfcc, axis=0),axis=0)\n",
    "    cct = torch.autograd.Variable(torch.from_numpy(cc.astype(float)).float())\n",
    "    return cct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-14.0856, -10.7070, -10.4366,  ...,  -7.9894, -10.8911, -15.0372],\n",
       "         [-23.4145, -10.6640,  -9.3113,  ..., -15.3147, -16.6253, -15.8784],\n",
       "         [-23.0852, -26.4813, -24.0595,  ..., -36.7484, -28.5153, -26.2736],\n",
       "         ...,\n",
       "         [-15.4084, -40.7633, -35.0773,  ...,  -6.2392,  -2.6497,   1.2092],\n",
       "         [  6.4542,   4.2020,   3.6008,  ..., -28.5293, -19.0213, -21.8093],\n",
       "         [ -1.5756,  -2.9960,  -0.5695,  ...,  -6.0823,  -0.3115,   2.0276]]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_audio_feat(path2mp3, method='psf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6044e+01, -1.8148e+01, -1.5037e+01,  ..., -1.1098e+01,\n",
       "         -1.3980e+01, -1.4588e+01],\n",
       "        [ 0.0000e+00, -1.1806e+01, -1.5878e+01,  ..., -1.0463e+01,\n",
       "         -2.4009e+01, -2.2678e+01],\n",
       "        [-3.2076e-14, -1.3636e+01, -2.6274e+01,  ..., -2.7164e+01,\n",
       "         -2.5822e+01, -2.1032e+01],\n",
       "        ...,\n",
       "        [-3.2777e-13,  2.0018e+00,  1.2092e+00,  ..., -2.9953e+01,\n",
       "         -2.0820e+01, -1.7548e+01],\n",
       "        [ 0.0000e+00,  9.2892e+00, -2.1809e+01,  ...,  1.1812e+01,\n",
       "         -1.8519e+00,  6.6752e+00],\n",
       "        [ 3.5948e-13, -1.3227e+01,  2.0276e+00,  ...,  7.3629e-01,\n",
       "         -4.6350e+00, -5.0158e+00]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(get_audio_feat(path2mp3, method='psf'), [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 573])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_audio_feat(path2mp3, method='librosa').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1552734e-05, 6.1035156e-05, 6.1035156e-05, ..., 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = librosa.load(path2mp3,sr=None)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10, -24, -35, ...,  -5,   7,  13], dtype=int16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate, sig = readMP3(path2mp3)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(get_audio_feat(path2mp3, method='psf'), get_audio_feat(path2mp3, method='librosa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-13.773326 , -13.73917  , -13.736883 , ..., -13.813982 ,\n",
       "        -13.81537  , -13.815215 ],\n",
       "       [-13.795713 , -13.773858 , -13.7577505, ..., -13.813632 ,\n",
       "        -13.815297 , -13.815288 ],\n",
       "       [-13.785141 , -13.799453 , -13.808878 , ..., -13.807434 ,\n",
       "        -13.815107 , -13.815192 ],\n",
       "       ...,\n",
       "       [-13.815437 , -13.815411 , -13.815408 , ..., -13.81551  ,\n",
       "        -13.815511 , -13.815511 ],\n",
       "       [-13.815511 , -13.815511 , -13.815511 , ..., -13.815511 ,\n",
       "        -13.815511 , -13.815511 ],\n",
       "       [-13.815511 , -13.815511 , -13.815511 , ..., -13.815511 ,\n",
       "        -13.815511 , -13.815511 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_audio_feat_librosa(path2mp3, feature='fbank', dim=26, cmvn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.94606475, 5.30000278, 5.43647196, ..., 6.61245851, 2.72615739,\n",
       "        2.67667794],\n",
       "       [2.59755188, 5.60831071, 5.4310289 , ..., 6.6993696 , 3.16617381,\n",
       "        2.85343087],\n",
       "       [2.1105837 , 5.67809607, 5.26407824, ..., 6.28173124, 1.76820534,\n",
       "        1.90300327],\n",
       "       ...,\n",
       "       [6.26139481, 8.2433599 , 9.6849295 , ..., 6.53663859, 5.04233776,\n",
       "        4.64273055],\n",
       "       [4.93133168, 5.24287202, 5.33836367, ..., 6.36564206, 5.8763119 ,\n",
       "        5.88703613],\n",
       "       [1.23639138, 2.64273511, 4.17202093, ..., 5.00450562, 3.48012979,\n",
       "        3.4426068 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbank_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2txt, 'r') as f:\n",
    "    content = f.readline()\n",
    "k = np.array([ord(c) - 32 for c in content.replace('Text:', '').strip()])\n",
    "k = torch.autograd.Variable(torch.from_numpy(k.astype(int)).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41,  0, 35, 33, 46,  7, 52,  0, 36, 37, 51, 35, 50, 41, 34, 37,  0, 52,\n",
       "        47,  0, 57, 47, 53,  0, 40, 47, 55,  0, 49, 53, 41, 35, 43, 44, 57,  0,\n",
       "        41,  0, 55, 33, 46, 52, 37, 36,  0, 52, 47,  0, 36, 41, 54, 37,  0, 41,\n",
       "        46, 52, 47,  0, 46, 53, 45, 34, 46, 37, 51, 51,  0, 39, 37, 52,  0, 33,\n",
       "        55, 33, 57,  0, 38, 50, 47, 45,  0, 52, 40, 37], dtype=torch.int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([37, 40, 52,  0, 45, 47, 50, 38,  0, 57, 33, 55, 33,  0, 52, 37, 39,  0,\n",
       "        51, 51, 37, 46, 34, 45, 53, 46,  0, 47, 52, 46, 41,  0, 37, 54, 41, 36,\n",
       "         0, 47, 52,  0, 36, 37, 52, 46, 33, 55,  0, 41,  0, 57, 44, 43, 35, 41,\n",
       "        53, 49,  0, 55, 47, 40,  0, 53, 47, 57,  0, 47, 52,  0, 37, 34, 41, 50,\n",
       "        35, 51, 37, 36,  0, 52,  7, 46, 33, 35,  0, 41], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(k, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', ' ', 'C', 'A', 'N', \"'\", 'T', ' ', 'D', 'E', 'S', 'C', 'R',\n",
       "       'I', 'B', 'E', ' ', 'T', 'O', ' ', 'Y', 'O', 'U', ' ', 'H', 'O',\n",
       "       'W', ' ', 'Q', 'U', 'I', 'C', 'K', 'L', 'Y', ' ', 'I', ' ', 'W',\n",
       "       'A', 'N', 'T', 'E', 'D', ' ', 'T', 'O', ' ', 'D', 'I', 'V', 'E',\n",
       "       ' ', 'I', 'N', 'T', 'O', ' ', 'N', 'U', 'M', 'B', 'N', 'E', 'S',\n",
       "       'S', ' ', 'G', 'E', 'T', ' ', 'A', 'W', 'A', 'Y', ' ', 'F', 'R',\n",
       "       'O', 'M', ' ', 'T', 'H', 'E'], dtype='<U1')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(lambda x: chr(x + 32), k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_as_tensor(txt_file):\n",
    "    with open(txt_file, 'r') as f:\n",
    "         content = f.readline()\n",
    "    ascii = np.array([ord(c) - 32 for c in content.replace('Text:', '').strip()])\n",
    "    ascii = np.append(ascii, [-2])\n",
    "    ascii = np.insert(ascii, 0, [-1])\n",
    "    ascii = np.expand_dims(ascii,axis=0)\n",
    "    ascii = torch.autograd.Variable(torch.from_numpy(ascii.astype(float)).float())\n",
    "    return ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., 41.,  0., 35., 33., 46.,  7., 52.,  0., 36., 37., 51., 35., 50.,\n",
       "         41., 34., 37.,  0., 52., 47.,  0., 57., 47., 53.,  0., 40., 47., 55.,\n",
       "          0., 49., 53., 41., 35., 43., 44., 57.,  0., 41.,  0., 55., 33., 46.,\n",
       "         52., 37., 36.,  0., 52., 47.,  0., 36., 41., 54., 37.,  0., 41., 46.,\n",
       "         52., 47.,  0., 46., 53., 45., 34., 46., 37., 51., 51.,  0., 39., 37.,\n",
       "         52.,  0., 33., 55., 33., 57.,  0., 38., 50., 47., 45.,  0., 52., 40.,\n",
       "         37., -2.]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_txt_as_tensor(path2txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory, extension):\n",
    "    return np.array(list((f for f in listdir(directory) if f.endswith('.' + extension))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3files = list_files('../data/dev/', 'mp3')\n",
    "txtfiles = list_files('../data/dev/', 'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(vec, pad, dim):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        vec - tensor to pad\n",
    "        pad - the size to pad to\n",
    "        dim - dimension to pad\n",
    "\n",
    "    return:\n",
    "        a new tensor padded to 'pad' in dimension 'dim'\n",
    "    \"\"\"\n",
    "    pad_size = list(vec.shape)\n",
    "    pad_size[dim] = pad - vec.size(dim)\n",
    "    return torch.cat([vec, torch.zeros(*pad_size)], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 615])\n",
      "torch.Size([1, 13, 604])\n",
      "\t2, 13, 615\n",
      "torch.Size([1, 13, 265])\n",
      "\t3, 13, 615\n",
      "torch.Size([1, 13, 489])\n",
      "\t4, 13, 615\n",
      "torch.Size([1, 13, 179])\n",
      "\t5, 13, 615\n",
      "torch.Size([1, 13, 226])\n",
      "\t6, 13, 615\n",
      "torch.Size([1, 13, 615])\n",
      "\t7, 13, 615\n",
      "torch.Size([1, 13, 179])\n",
      "\t8, 13, 615\n",
      "torch.Size([1, 13, 442])\n",
      "\t9, 13, 615\n",
      "torch.Size([1, 13, 276])\n",
      "\t10, 13, 615\n",
      "torch.Size([1, 13, 564])\n",
      "\t11, 13, 615\n",
      "torch.Size([1, 13, 136])\n",
      "\t12, 13, 615\n",
      "torch.Size([1, 13, 579])\n",
      "\t13, 13, 615\n",
      "torch.Size([1, 13, 316])\n",
      "\t14, 13, 615\n",
      "torch.Size([1, 13, 269])\n",
      "\t15, 13, 615\n",
      "torch.Size([1, 13, 615])\n",
      "\t16, 13, 615\n",
      "torch.Size([1, 13, 175])\n",
      "\t17, 13, 615\n",
      "torch.Size([1, 13, 201])\n",
      "\t18, 13, 615\n",
      "torch.Size([1, 13, 366])\n",
      "\t19, 13, 615\n",
      "torch.Size([1, 13, 103])\n",
      "\t20, 13, 615\n",
      "torch.Size([1, 13, 201])\n",
      "\t21, 13, 615\n",
      "torch.Size([1, 13, 294])\n",
      "\t22, 13, 615\n",
      "torch.Size([1, 13, 327])\n",
      "\t23, 13, 615\n",
      "torch.Size([1, 13, 525])\n",
      "\t24, 13, 615\n",
      "torch.Size([1, 13, 597])\n",
      "\t25, 13, 615\n",
      "torch.Size([1, 13, 323])\n",
      "\t26, 13, 615\n",
      "torch.Size([1, 13, 226])\n",
      "\t27, 13, 615\n",
      "torch.Size([1, 13, 136])\n",
      "\t28, 13, 615\n",
      "torch.Size([1, 13, 161])\n",
      "\t29, 13, 615\n",
      "torch.Size([1, 13, 615])\n",
      "\t30, 13, 615\n",
      "torch.Size([1, 13, 546])\n",
      "\t31, 13, 615\n",
      "torch.Size([1, 13, 579])\n",
      "\t32, 13, 615\n",
      "torch.Size([1, 13, 341])\n",
      "\t33, 13, 615\n",
      "torch.Size([1, 13, 211])\n",
      "\t34, 13, 615\n",
      "torch.Size([1, 13, 96])\n",
      "\t35, 13, 615\n",
      "torch.Size([1, 13, 193])\n",
      "\t36, 13, 615\n",
      "torch.Size([1, 13, 309])\n",
      "\t37, 13, 615\n",
      "torch.Size([1, 13, 373])\n",
      "\t38, 13, 615\n",
      "torch.Size([1, 13, 150])\n",
      "\t39, 13, 615\n",
      "torch.Size([1, 13, 384])\n",
      "\t40, 13, 615\n",
      "torch.Size([1, 13, 611])\n",
      "\t41, 13, 615\n",
      "torch.Size([1, 13, 168])\n",
      "\t42, 13, 615\n",
      "torch.Size([1, 13, 622])\n",
      "\t43, 13, 622\n",
      "torch.Size([1, 13, 391])\n",
      "\t44, 13, 622\n",
      "torch.Size([1, 13, 359])\n",
      "\t45, 13, 622\n",
      "torch.Size([1, 13, 118])\n",
      "\t46, 13, 622\n",
      "torch.Size([1, 13, 168])\n",
      "\t47, 13, 622\n",
      "torch.Size([1, 13, 323])\n",
      "\t48, 13, 622\n",
      "torch.Size([1, 13, 424])\n",
      "\t49, 13, 622\n",
      "torch.Size([1, 13, 168])\n",
      "\t50, 13, 622\n",
      "torch.Size([1, 13, 143])\n",
      "\t51, 13, 622\n",
      "torch.Size([1, 13, 579])\n",
      "\t52, 13, 622\n",
      "torch.Size([1, 13, 327])\n",
      "\t53, 13, 622\n",
      "torch.Size([1, 13, 226])\n",
      "\t54, 13, 622\n",
      "torch.Size([1, 13, 211])\n",
      "\t55, 13, 622\n",
      "torch.Size([1, 13, 615])\n",
      "\t56, 13, 622\n",
      "torch.Size([1, 13, 161])\n",
      "\t57, 13, 622\n",
      "torch.Size([1, 13, 611])\n",
      "\t58, 13, 622\n",
      "torch.Size([1, 13, 406])\n",
      "\t59, 13, 622\n",
      "torch.Size([1, 13, 597])\n",
      "\t60, 13, 622\n",
      "torch.Size([1, 13, 129])\n",
      "\t61, 13, 622\n",
      "torch.Size([1, 13, 589])\n",
      "\t62, 13, 622\n",
      "torch.Size([1, 13, 265])\n",
      "\t63, 13, 622\n",
      "torch.Size([1, 13, 597])\n",
      "\t64, 13, 622\n",
      "torch.Size([1, 13, 150])\n",
      "\t65, 13, 622\n",
      "torch.Size([1, 13, 276])\n",
      "\t66, 13, 622\n",
      "torch.Size([1, 13, 629])\n",
      "\t67, 13, 629\n",
      "torch.Size([1, 13, 316])\n",
      "\t68, 13, 629\n",
      "torch.Size([1, 13, 129])\n",
      "\t69, 13, 629\n",
      "torch.Size([1, 13, 226])\n",
      "\t70, 13, 629\n",
      "torch.Size([1, 13, 352])\n",
      "\t71, 13, 629\n",
      "torch.Size([1, 13, 143])\n",
      "\t72, 13, 629\n",
      "torch.Size([1, 13, 201])\n",
      "\t73, 13, 629\n",
      "torch.Size([1, 13, 615])\n",
      "\t74, 13, 629\n",
      "torch.Size([1, 13, 622])\n",
      "\t75, 13, 629\n",
      "torch.Size([1, 13, 629])\n",
      "\t76, 13, 629\n",
      "torch.Size([1, 13, 150])\n",
      "\t77, 13, 629\n",
      "torch.Size([1, 13, 611])\n",
      "\t78, 13, 629\n",
      "torch.Size([1, 13, 237])\n",
      "\t79, 13, 629\n",
      "torch.Size([1, 13, 226])\n",
      "\t80, 13, 629\n",
      "torch.Size([1, 13, 539])\n",
      "\t81, 13, 629\n",
      "torch.Size([1, 13, 629])\n",
      "\t82, 13, 629\n",
      "torch.Size([1, 13, 629])\n",
      "\t83, 13, 629\n",
      "torch.Size([1, 13, 129])\n",
      "\t84, 13, 629\n",
      "torch.Size([1, 13, 118])\n",
      "\t85, 13, 629\n",
      "torch.Size([1, 13, 571])\n",
      "\t86, 13, 629\n",
      "torch.Size([1, 13, 611])\n",
      "\t87, 13, 629\n",
      "torch.Size([1, 13, 193])\n",
      "\t88, 13, 629\n",
      "torch.Size([1, 13, 193])\n",
      "\t89, 13, 629\n",
      "torch.Size([1, 13, 211])\n",
      "\t90, 13, 629\n",
      "torch.Size([1, 13, 352])\n",
      "\t91, 13, 629\n",
      "torch.Size([1, 13, 615])\n",
      "\t92, 13, 629\n",
      "torch.Size([1, 13, 251])\n",
      "\t93, 13, 629\n",
      "torch.Size([1, 13, 615])\n",
      "\t94, 13, 629\n",
      "torch.Size([1, 13, 291])\n",
      "\t95, 13, 629\n",
      "torch.Size([1, 13, 211])\n",
      "\t96, 13, 629\n",
      "torch.Size([1, 13, 211])\n",
      "\t97, 13, 629\n",
      "torch.Size([1, 13, 622])\n",
      "\t98, 13, 629\n",
      "torch.Size([1, 13, 622])\n",
      "\t99, 13, 629\n",
      "torch.Size([1, 13, 431])\n",
      "\t100, 13, 629\n",
      "torch.Size([1, 13, 352])\n",
      "\t101, 13, 629\n",
      "torch.Size([1, 13, 201])\n",
      "\t102, 13, 629\n",
      "torch.Size([1, 13, 276])\n",
      "\t103, 13, 629\n",
      "torch.Size([1, 13, 521])\n",
      "\t104, 13, 629\n",
      "torch.Size([1, 13, 622])\n",
      "\t105, 13, 629\n",
      "torch.Size([1, 13, 615])\n",
      "\t106, 13, 629\n",
      "torch.Size([1, 13, 582])\n",
      "\t107, 13, 629\n",
      "torch.Size([1, 13, 553])\n",
      "\t108, 13, 629\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "for mp3file in mp3files:\n",
    "    mp3tensor = get_audio_feat('../data/dev/' + mp3file)\n",
    "    print(mp3tensor.shape)\n",
    "    if (f > 0):\n",
    "        if (mp3tensor.shape[2] > mp3tensors.shape[2]):\n",
    "            mp3tensors = pad_tensor(mp3tensors, mp3tensor.shape[2], 2)\n",
    "        elif (mp3tensor.shape[2] < mp3tensors.shape[2]):\n",
    "            mp3tensor = pad_tensor(mp3tensor, mp3tensors.shape[2], 2)\n",
    "        mp3tensors = torch.cat((mp3tensors,  mp3tensor), 0)\n",
    "        print(\"\\t%s, %s, %s\" % (mp3tensors.shape[0], mp3tensors.shape[1], mp3tensors.shape[2]))\n",
    "    else:\n",
    "        mp3tensors = mp3tensor\n",
    "    f = f + 1\n",
    "    #if f == 5:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 13, 629])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28])\n",
      "torch.Size([1, 34])\n",
      "\t2, 34\n",
      "torch.Size([1, 21])\n",
      "\t3, 34\n",
      "torch.Size([1, 58])\n",
      "\t4, 58\n",
      "torch.Size([1, 120])\n",
      "\t5, 120\n",
      "torch.Size([1, 50])\n",
      "\t6, 120\n",
      "torch.Size([1, 53])\n",
      "\t7, 120\n",
      "torch.Size([1, 28])\n",
      "\t8, 120\n",
      "torch.Size([1, 79])\n",
      "\t9, 120\n",
      "torch.Size([1, 114])\n",
      "\t10, 120\n",
      "torch.Size([1, 44])\n",
      "\t11, 120\n",
      "torch.Size([1, 21])\n",
      "\t12, 120\n",
      "torch.Size([1, 74])\n",
      "\t13, 120\n",
      "torch.Size([1, 72])\n",
      "\t14, 120\n",
      "torch.Size([1, 97])\n",
      "\t15, 120\n",
      "torch.Size([1, 30])\n",
      "\t16, 120\n",
      "torch.Size([1, 82])\n",
      "\t17, 120\n",
      "torch.Size([1, 42])\n",
      "\t18, 120\n",
      "torch.Size([1, 40])\n",
      "\t19, 120\n",
      "torch.Size([1, 45])\n",
      "\t20, 120\n",
      "torch.Size([1, 20])\n",
      "\t21, 120\n",
      "torch.Size([1, 86])\n",
      "\t22, 120\n",
      "torch.Size([1, 106])\n",
      "\t23, 120\n",
      "torch.Size([1, 20])\n",
      "\t24, 120\n",
      "torch.Size([1, 90])\n",
      "\t25, 120\n",
      "torch.Size([1, 19])\n",
      "\t26, 120\n",
      "torch.Size([1, 101])\n",
      "\t27, 120\n",
      "torch.Size([1, 122])\n",
      "\t28, 122\n",
      "torch.Size([1, 26])\n",
      "\t29, 122\n",
      "torch.Size([1, 108])\n",
      "\t30, 122\n",
      "torch.Size([1, 24])\n",
      "\t31, 122\n",
      "torch.Size([1, 64])\n",
      "\t32, 122\n",
      "torch.Size([1, 32])\n",
      "\t33, 122\n",
      "torch.Size([1, 114])\n",
      "\t34, 122\n",
      "torch.Size([1, 52])\n",
      "\t35, 122\n",
      "torch.Size([1, 39])\n",
      "\t36, 122\n",
      "torch.Size([1, 107])\n",
      "\t37, 122\n",
      "torch.Size([1, 52])\n",
      "\t38, 122\n",
      "torch.Size([1, 55])\n",
      "\t39, 122\n",
      "torch.Size([1, 139])\n",
      "\t40, 139\n",
      "torch.Size([1, 131])\n",
      "\t41, 139\n",
      "torch.Size([1, 73])\n",
      "\t42, 139\n",
      "torch.Size([1, 37])\n",
      "\t43, 139\n",
      "torch.Size([1, 33])\n",
      "\t44, 139\n",
      "torch.Size([1, 37])\n",
      "\t45, 139\n",
      "torch.Size([1, 114])\n",
      "\t46, 139\n",
      "torch.Size([1, 105])\n",
      "\t47, 139\n",
      "torch.Size([1, 73])\n",
      "\t48, 139\n",
      "torch.Size([1, 102])\n",
      "\t49, 139\n",
      "torch.Size([1, 138])\n",
      "\t50, 139\n",
      "torch.Size([1, 55])\n",
      "\t51, 139\n",
      "torch.Size([1, 44])\n",
      "\t52, 139\n",
      "torch.Size([1, 116])\n",
      "\t53, 139\n",
      "torch.Size([1, 70])\n",
      "\t54, 139\n",
      "torch.Size([1, 107])\n",
      "\t55, 139\n",
      "torch.Size([1, 86])\n",
      "\t56, 139\n",
      "torch.Size([1, 41])\n",
      "\t57, 139\n",
      "torch.Size([1, 109])\n",
      "\t58, 139\n",
      "torch.Size([1, 28])\n",
      "\t59, 139\n",
      "torch.Size([1, 17])\n",
      "\t60, 139\n",
      "torch.Size([1, 71])\n",
      "\t61, 139\n",
      "torch.Size([1, 44])\n",
      "\t62, 139\n",
      "torch.Size([1, 70])\n",
      "\t63, 139\n",
      "torch.Size([1, 36])\n",
      "\t64, 139\n",
      "torch.Size([1, 84])\n",
      "\t65, 139\n",
      "torch.Size([1, 43])\n",
      "\t66, 139\n",
      "torch.Size([1, 39])\n",
      "\t67, 139\n",
      "torch.Size([1, 36])\n",
      "\t68, 139\n",
      "torch.Size([1, 97])\n",
      "\t69, 139\n",
      "torch.Size([1, 75])\n",
      "\t70, 139\n",
      "torch.Size([1, 111])\n",
      "\t71, 139\n",
      "torch.Size([1, 130])\n",
      "\t72, 139\n",
      "torch.Size([1, 46])\n",
      "\t73, 139\n",
      "torch.Size([1, 84])\n",
      "\t74, 139\n",
      "torch.Size([1, 70])\n",
      "\t75, 139\n",
      "torch.Size([1, 99])\n",
      "\t76, 139\n",
      "torch.Size([1, 32])\n",
      "\t77, 139\n",
      "torch.Size([1, 21])\n",
      "\t78, 139\n",
      "torch.Size([1, 102])\n",
      "\t79, 139\n",
      "torch.Size([1, 40])\n",
      "\t80, 139\n",
      "torch.Size([1, 78])\n",
      "\t81, 139\n",
      "torch.Size([1, 53])\n",
      "\t82, 139\n",
      "torch.Size([1, 110])\n",
      "\t83, 139\n",
      "torch.Size([1, 101])\n",
      "\t84, 139\n",
      "torch.Size([1, 51])\n",
      "\t85, 139\n",
      "torch.Size([1, 38])\n",
      "\t86, 139\n",
      "torch.Size([1, 18])\n",
      "\t87, 139\n",
      "torch.Size([1, 23])\n",
      "\t88, 139\n",
      "torch.Size([1, 47])\n",
      "\t89, 139\n",
      "torch.Size([1, 61])\n",
      "\t90, 139\n",
      "torch.Size([1, 31])\n",
      "\t91, 139\n",
      "torch.Size([1, 70])\n",
      "\t92, 139\n",
      "torch.Size([1, 60])\n",
      "\t93, 139\n",
      "torch.Size([1, 17])\n",
      "\t94, 139\n",
      "torch.Size([1, 17])\n",
      "\t95, 139\n",
      "torch.Size([1, 35])\n",
      "\t96, 139\n",
      "torch.Size([1, 27])\n",
      "\t97, 139\n",
      "torch.Size([1, 29])\n",
      "\t98, 139\n",
      "torch.Size([1, 57])\n",
      "\t99, 139\n",
      "torch.Size([1, 21])\n",
      "\t100, 139\n",
      "torch.Size([1, 83])\n",
      "\t101, 139\n",
      "torch.Size([1, 33])\n",
      "\t102, 139\n",
      "torch.Size([1, 69])\n",
      "\t103, 139\n",
      "torch.Size([1, 48])\n",
      "\t104, 139\n",
      "torch.Size([1, 56])\n",
      "\t105, 139\n",
      "torch.Size([1, 108])\n",
      "\t106, 139\n",
      "torch.Size([1, 18])\n",
      "\t107, 139\n",
      "torch.Size([1, 88])\n",
      "\t108, 139\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "for txtfile in txtfiles:\n",
    "    txttensor = get_txt_as_tensor('../data/dev/' + txtfile)\n",
    "    print(txttensor.shape)\n",
    "    if (f > 0):\n",
    "        if (txttensor.shape[1] > txttensors.shape[1]):\n",
    "            txttensors = pad_tensor(txttensors, txttensor.shape[1], 1)\n",
    "        elif (txttensor.shape[1] < txttensors.shape[1]):\n",
    "            txttensor = pad_tensor(txttensor, txttensors.shape[1], 1)\n",
    "        txttensors = torch.cat((txttensors,  txttensor), 0)\n",
    "        print(\"\\t%s, %s\" % (txttensors.shape[0], txttensors.shape[1]))\n",
    "    else:\n",
    "        txttensors = txttensor\n",
    "    f = f + 1\n",
    "    #if f == 5:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 139])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txttensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.checkpoint import checkpoint_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(input_size=13, hidden_size=256, nb_layers=3, batch_first=True):\n",
    "\n",
    "    rnns = []\n",
    "    #batch_norm = SequenceWise(nn.BatchNorm1d(input_size)) if batch_norm else None\n",
    "    rnn = nn.LSTM(input_size, hidden_size, nb_layers, batch_first) #hidden_size=768, bidirectional=False, bias=True\n",
    "    #rnn = nn.LSTM(input_size=13, hidden_size=768, bidirectional=False, bias=True)\n",
    "    #rnns.append(('0', rnn))\n",
    "    #for x in range(nb_layers - 1):\n",
    "    #    rnn = nn.LSTM(input_size=13, hidden_size=768, bidirectional=False, bias=True)\n",
    "    #    rnns.append(('%d' % (x + 1), rnn))\n",
    "    #rnns = nn.Sequential(OrderedDict(rnns))\n",
    "\n",
    "    fully_connected = nn.Sequential(\n",
    "        nn.LSTM(input_size, hidden_size, nb_layers, batch_first),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.Linear(256, 108, bias=False)\n",
    "        #,nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "    #for x in rnns:\n",
    "    #    x.flatten_parameters()\n",
    "\n",
    "    #return rnns\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size=13, hidden_size=256, num_layers=3, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected = nn.Sequential(\n",
    "        nn.BatchNorm1d(161024),\n",
    "        nn.Linear(161024, 139, bias=False),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "fully_connected2 = nn.Sequential(\n",
    "        nn.BatchNorm1d(629),\n",
    "        nn.Linear(256, 1, bias=False),\n",
    "        nn.Softmax(dim=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(13, 256, num_layers=3)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "param = list(rnn.parameters()) + list(fully_connected.parameters())\n",
    "optimiser = torch.optim.Adam(param, lr=learning_rate, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 629, 13])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3tensorsp = mp3tensors.permute(0, 2, 1)\n",
    "mp3tensorsp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 139, 13])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3tensorsp = mp3tensorsp[:, 0:139, :]\n",
    "mp3tensorsp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 139, 1])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txttensorsp = txttensors\n",
    "txttensorsp.unsqueeze_(-1)\n",
    "txttensorsp = txttensorsp.expand(108, 139, 1)\n",
    "txttensorsp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.rand(3, 108, 256)\n",
    "c0 = torch.rand(3, 108, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "txttensors = txttensors.view(108, 139).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 139])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txttensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, 34, 53, 52,  0, 41, 38,  0, 57, 47, 53,  0, 52, 47, 47, 43,  0, 52,\n",
       "        40, 41, 51,  0, 19, 16,  0, 48, 37, 50, 35, 37, 46, 52,  0, 52, 40, 37,\n",
       "        51, 37,  0, 19, 16, 16,  0, 48, 37, 47, 48, 44, 37,  0, 33, 46, 36,  0,\n",
       "        40, 33, 36,  0, 52, 40, 37, 45,  0, 46, 47, 45, 41, 46, 33, 52, 37,  0,\n",
       "        52, 40, 37, 41, 50,  0, 38, 50, 41, 37, 46, 36, 51,  0, 33, 46, 36,  0,\n",
       "        52, 47, 47, 43,  0, 52, 40, 37,  0, 51, 33, 45, 37,  0, 46, 53, 45, 34,\n",
       "        37, 50,  0, 47, 38, -2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txttensors[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([108, 161024])\n",
      "torch.Size([108, 139])\n",
      "torch.Size([108, 139])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/ClassNLLCriterion.c:21",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-74deca6d8004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxttensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#assert False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxttensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/ClassNLLCriterion.c:21"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Clear stored gradient\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    #model.hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    test = mp3tensorsp[9].view(1, *mp3tensorsp[9].size())\n",
    "#     print(mp3tensorsp.size())\n",
    "    \n",
    "    rnn_out, hidden = rnn(mp3tensorsp, (h0, c0))\n",
    "    rnn_out = rnn_out.contiguous().view(rnn_out.size(0),-1)\n",
    "    print(rnn_out.size())\n",
    "#     print(rnn_out)\n",
    "#     print('RNN _OUT ')\n",
    "#     print(rnn_out.size())\n",
    "    fc_out = fully_connected(rnn_out)\n",
    "    print(fc_out.size())\n",
    "    #fc_out = fc_out.permute(0, 2, 1)\n",
    "#     print(fc_out.size())\n",
    "    \n",
    "#     y_pred = model(test)\n",
    "    #print(txttensorsp.size())\n",
    "#     print(y_pred[0].size())\n",
    "    print(txttensors.size())\n",
    "    #assert False\n",
    "    loss = loss_fn(fc_out, txttensors)\n",
    "    #assert False\n",
    "    if t % 20 == 0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected = nn.Sequential(\n",
    "        nn.BatchNorm1d(629),\n",
    "        nn.Linear(256, 1, bias=False),\n",
    "        nn.Linear(256, 1, bias=False),\n",
    "        nn.Softmax(dim=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -3.7671, -18.7749, -35.1914,   8.1286, -26.1182,  30.0746, -29.1513,\n",
       "         16.6291,  -8.0482,  13.3221,  -8.8879,   0.8081,  -1.6713])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3tensorsp[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0127], grad_fn=<TopkBackward>), tensor([75]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(fc_out[0][9], k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842., 10473842., 10473842.,\n",
       "       10473842., 10473842., 10473842., 10473842.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_index_dict():\n",
    "    index_list = [i for i in range(len(__char_list))]\n",
    "    __index_of_str = dict(zip(__char_list, index_list))\n",
    "    __char_of_index = dict(zip(index_list, __char_list))\n",
    "    __total_num = index_list[-1] + 1\n",
    "    return __index_of_str, __char_of_index, __total_num\n",
    "\n",
    "def get_index_of(character):\n",
    "    return __index_of_str[character]\n",
    "\n",
    "def get_char_of(index):\n",
    "    return __char_of_index[index]\n",
    "\n",
    "def get_total_num():\n",
    "    return __total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "__char_list = (\n",
    "    'A',\n",
    "    'B',\n",
    "    'C',\n",
    "    'D',\n",
    "    'E',\n",
    "    'F',\n",
    "    'G',\n",
    "    'H',\n",
    "    'I',\n",
    "    'J',\n",
    "    'K',\n",
    "    'L',\n",
    "    'M',\n",
    "    'N',\n",
    "    'O',\n",
    "    'P',\n",
    "    'Q',\n",
    "    'R',\n",
    "    'S',\n",
    "    'T',\n",
    "    'U',\n",
    "    'V',\n",
    "    'W',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "    '7',\n",
    "    '8',\n",
    "    '9',\n",
    "    '0',\n",
    "    '<sos>',\n",
    "    '<eos>',\n",
    "    '<pad>',\n",
    "    '\\'',\n",
    ")\n",
    "__index_of_str, __char_of_index, __total_num = _init_index_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25,\n",
       " '1': 26,\n",
       " '2': 27,\n",
       " '3': 28,\n",
       " '4': 29,\n",
       " '5': 30,\n",
       " '6': 31,\n",
       " '7': 32,\n",
       " '8': 33,\n",
       " '9': 34,\n",
       " '0': 35,\n",
       " '<sos>': 36,\n",
       " '<eos>': 37,\n",
       " '<pad>': 38,\n",
       " \"'\": 39}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__index_of_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A',\n",
       " 1: 'B',\n",
       " 2: 'C',\n",
       " 3: 'D',\n",
       " 4: 'E',\n",
       " 5: 'F',\n",
       " 6: 'G',\n",
       " 7: 'H',\n",
       " 8: 'I',\n",
       " 9: 'J',\n",
       " 10: 'K',\n",
       " 11: 'L',\n",
       " 12: 'M',\n",
       " 13: 'N',\n",
       " 14: 'O',\n",
       " 15: 'P',\n",
       " 16: 'Q',\n",
       " 17: 'R',\n",
       " 18: 'S',\n",
       " 19: 'T',\n",
       " 20: 'U',\n",
       " 21: 'V',\n",
       " 22: 'W',\n",
       " 23: 'X',\n",
       " 24: 'Y',\n",
       " 25: 'Z',\n",
       " 26: '1',\n",
       " 27: '2',\n",
       " 28: '3',\n",
       " 29: '4',\n",
       " 30: '5',\n",
       " 31: '6',\n",
       " 32: '7',\n",
       " 33: '8',\n",
       " 34: '9',\n",
       " 35: '0',\n",
       " 36: '<sos>',\n",
       " 37: '<eos>',\n",
       " 38: '<pad>',\n",
       " 39: \"'\"}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__char_of_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
